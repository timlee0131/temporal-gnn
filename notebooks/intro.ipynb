{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Torch Spatio-Temporal (TSL)\n",
    "official documentation: https://torch-spatiotemporal.readthedocs.io/en/latest/index.html\n",
    "\n",
    "purpose of this notebook:\n",
    "- data structures\n",
    "- datasets\n",
    "- models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsl\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tsl.datasets import PeMS04, PeMS07, PeMS08, PemsBay\n",
    "from tsl.datasets import MetrLA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsl version  : 0.9.5\n",
      "torch version: 2.4.0+cu121\n",
      "torch_geometric version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"tsl version  : {tsl.__version__}\")\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torch_geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "download: 0.00B [00:00, ?B/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 503: Service Unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_PeMS04 \u001b[38;5;241m=\u001b[39m \u001b[43mPeMS04\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/PeMS04\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_benchmarks.py:27\u001b[0m, in \u001b[0;36m_PeMS.__init__\u001b[0;34m(self, mask_zeros, root, freq)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_zeros \u001b[38;5;241m=\u001b[39m mask_zeros\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# load dataset\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m flow, occupancy, speed, dist, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_zeros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(target\u001b[38;5;241m=\u001b[39mflow,\n\u001b[1;32m     29\u001b[0m                  mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m     30\u001b[0m                  freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[1;32m     31\u001b[0m                  similarity_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m                  temporal_aggregation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m                  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# todo : remove this hack\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_benchmarks.py:84\u001b[0m, in \u001b[0;36m_PeMS.load\u001b[0;34m(self, mask_zeros)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, mask_zeros: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;241m*\u001b[39mdfs, dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask_zeros:\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_benchmarks.py:55\u001b[0m, in \u001b[0;36m_PeMS.load_raw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     fp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_files_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m fp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/prototypes/dataset.py:237\u001b[0m, in \u001b[0;36mDataset.maybe_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files_exist(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_files_paths_list):\n\u001b[1;32m    236\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_benchmarks.py:50\u001b[0m, in \u001b[0;36m_PeMS.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Build dataset\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_distance_matrix(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_sensors)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_downloads()\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/prototypes/dataset.py:232\u001b[0m, in \u001b[0;36mDataset.maybe_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files_exist(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_files_paths_list):\n\u001b[1;32m    231\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_benchmarks.py:44\u001b[0m, in \u001b[0;36m_PeMS.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     extract_zip(path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir)\n\u001b[1;32m     46\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(path)\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/utils/io.py:137\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, folder, filename, log)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# From https://stackoverflow.com/a/53877507\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DownloadProgressBar(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    134\u001b[0m                          unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m                          miniters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    136\u001b[0m                          desc\u001b[38;5;241m=\u001b[39murl\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:241\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    242\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/torch-st/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 503: Service Unavailable"
     ]
    }
   ],
   "source": [
    "dataset_PeMS04 = PeMS04(root='data/PeMS04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling period: <5 * Minutes>\n",
      "Has missing values: True\n",
      "Percentage of missing values: 8.11%\n",
      "Has exogenous variables: True\n",
      "Covariates: dist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/metr_la.py:98: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  date_range = pd.date_range(df.index[0], df.index[-1], freq='5T')\n",
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/metr_la.py:109: FutureWarning: The 'method' keyword in DataFrame.replace is deprecated and will be removed in a future version.\n",
      "  df = df.replace(to_replace=0., method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetrLA(length=34272, n_nodes=207, n_channels=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_MetrLA = MetrLA(root='data/MetrLA')\n",
    "\n",
    "print(f\"Sampling period: {dataset_MetrLA.freq}\")\n",
    "print(f\"Has missing values: {dataset_MetrLA.has_mask}\")\n",
    "print(f\"Percentage of missing values: {(1 - dataset_MetrLA.mask.mean()) * 100:.2f}%\")\n",
    "print(f\"Has exogenous variables: {dataset_MetrLA.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset_MetrLA.covariates.keys())}\")\n",
    "\n",
    "dataset_MetrLA  # type tsl.datasets.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling period: <5 * Minutes>\n",
      "Has missing values: True\n",
      "Percentage of missing values: 0.03%\n",
      "Has exogenous variables: True\n",
      "Covariates: dist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_bay.py:84: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  date_range = pd.date_range(df.index[0], df.index[-1], freq='5T')\n",
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/datasets/pems_bay.py:96: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', axis=0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PemsBay(length=52128, n_nodes=325, n_channels=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pemsbay = PemsBay(root='data/PemsBay')\n",
    "\n",
    "print(f\"Sampling period: {dataset_pemsbay.freq}\")\n",
    "print(f\"Has missing values: {dataset_pemsbay.has_mask}\")\n",
    "print(f\"Percentage of missing values: {(1 - dataset_pemsbay.mask.mean()) * 100:.2f}%\")\n",
    "print(f\"Has exogenous variables: {dataset_pemsbay.has_covariates}\")\n",
    "print(f\"Covariates: {', '.join(dataset_pemsbay.covariates.keys())}\")\n",
    "\n",
    "dataset_pemsbay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.      inf     inf ...     inf  8114.8 10009.7]\n",
      " [    inf     0.   2504.6 ...     inf     inf     inf]\n",
      " [    inf  1489.3     0.  ...     inf     inf  9837. ]\n",
      " ...\n",
      " [    inf     inf     inf ...     0.      inf     inf]\n",
      " [ 9599.8     inf     inf ...     inf     0.      inf]\n",
      " [10119.9  9374.8     inf ...     inf  9018.7     0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_MetrLA.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default similarity: distance\n",
      "Available similarity options: {'distance'}\n",
      "==========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(207, 207)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Default similarity: {dataset_MetrLA.similarity_score}\")\n",
    "print(f\"Available similarity options: {dataset_MetrLA.similarity_options}\")\n",
    "print(\"==========================================\")\n",
    "\n",
    "sim = dataset_MetrLA.get_similarity(\"distance\")  # or dataset_MetrLA.compute_similarity()\n",
    "\n",
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1515), (1515,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_connectivity uses get_similarity under the hood\n",
    "connectivity = dataset_MetrLA.get_connectivity(threshold=0.1, include_self=False, normalize_axis=1, layout=\"edge_index\")\n",
    "\n",
    "connectivity[0].shape, connectivity[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a torch-ready dataset\n",
    "\n",
    "convert dataset_MetrLA in (tsl.datasets.Dataset) format to (tsl.data.SpatioTemporalDataset) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.data import SpatioTemporalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <th>773869</th>\n",
       "      <th>767541</th>\n",
       "      <th>767542</th>\n",
       "      <th>717447</th>\n",
       "      <th>717446</th>\n",
       "      <th>717445</th>\n",
       "      <th>773062</th>\n",
       "      <th>767620</th>\n",
       "      <th>737529</th>\n",
       "      <th>717816</th>\n",
       "      <th>...</th>\n",
       "      <th>772167</th>\n",
       "      <th>769372</th>\n",
       "      <th>774204</th>\n",
       "      <th>769806</th>\n",
       "      <th>717590</th>\n",
       "      <th>717592</th>\n",
       "      <th>717595</th>\n",
       "      <th>772168</th>\n",
       "      <th>718141</th>\n",
       "      <th>769373</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channels</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:00:00</th>\n",
       "      <td>64.375000</td>\n",
       "      <td>67.625000</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>66.875000</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>65.125</td>\n",
       "      <td>67.125</td>\n",
       "      <td>59.625000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.625000</td>\n",
       "      <td>65.500</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>66.428574</td>\n",
       "      <td>66.875</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>61.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:05:00</th>\n",
       "      <td>62.666668</td>\n",
       "      <td>68.555557</td>\n",
       "      <td>65.444443</td>\n",
       "      <td>62.444443</td>\n",
       "      <td>64.444443</td>\n",
       "      <td>68.111115</td>\n",
       "      <td>65.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>57.444443</td>\n",
       "      <td>63.333332</td>\n",
       "      <td>...</td>\n",
       "      <td>50.666668</td>\n",
       "      <td>69.875</td>\n",
       "      <td>66.666664</td>\n",
       "      <td>58.555557</td>\n",
       "      <td>62.000</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>64.444443</td>\n",
       "      <td>55.888889</td>\n",
       "      <td>68.444443</td>\n",
       "      <td>62.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:10:00</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>64.500</td>\n",
       "      <td>64.250</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>68.125</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>61.375000</td>\n",
       "      <td>69.857140</td>\n",
       "      <td>62.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:15:00</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>64.500</td>\n",
       "      <td>64.250</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>68.125</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>61.375000</td>\n",
       "      <td>69.857140</td>\n",
       "      <td>62.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01 00:20:00</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>64.500</td>\n",
       "      <td>64.250</td>\n",
       "      <td>63.875000</td>\n",
       "      <td>65.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.125000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>68.125</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>65.625000</td>\n",
       "      <td>61.375000</td>\n",
       "      <td>69.857140</td>\n",
       "      <td>62.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "nodes                   773869     767541     767542     717447     717446  \\\n",
       "channels                     0          0          0          0          0   \n",
       "2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
       "2012-03-01 00:05:00  62.666668  68.555557  65.444443  62.444443  64.444443   \n",
       "2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
       "2012-03-01 00:15:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
       "2012-03-01 00:20:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
       "\n",
       "nodes                   717445  773062  767620     737529     717816  ...  \\\n",
       "channels                     0       0       0          0          0  ...   \n",
       "2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n",
       "2012-03-01 00:05:00  68.111115  65.000  65.000  57.444443  63.333332  ...   \n",
       "2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
       "2012-03-01 00:15:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
       "2012-03-01 00:20:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
       "\n",
       "nodes                   772167  769372     774204     769806  717590  \\\n",
       "channels                     0       0          0          0       0   \n",
       "2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428574  66.875   \n",
       "2012-03-01 00:05:00  50.666668  69.875  66.666664  58.555557  62.000   \n",
       "2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
       "2012-03-01 00:15:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
       "2012-03-01 00:20:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
       "\n",
       "nodes                   717592     717595     772168     718141  769373  \n",
       "channels                     0          0          0          0       0  \n",
       "2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n",
       "2012-03-01 00:05:00  61.111111  64.444443  55.888889  68.444443  62.875  \n",
       "2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857140  62.000  \n",
       "2012-03-01 00:15:00  62.500000  65.625000  61.375000  69.857140  62.000  \n",
       "2012-03-01 00:20:00  62.500000  65.625000  61.375000  69.857140  62.000  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset_MetrLA.dataframe()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalDataset(n_samples=34249, n_nodes=207, n_channels=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subclass of torch.utils.data.Dataset\n",
    "torch_dataset = SpatioTemporalDataset(\n",
    "    target=dataset_MetrLA.dataframe(),\n",
    "    connectivity=connectivity,\n",
    "    mask=dataset_MetrLA.mask,\n",
    "    horizon=6,\n",
    "    window=18,\n",
    "    stride=1\n",
    ")\n",
    "\n",
    "torch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18, 207, 1]),\n",
       " Data(\n",
       "   input=(x=[t=18, n=207, f=1], edge_index=[2, e=1515], edge_weight=[e=1515]),\n",
       "   target=(y=[t=6, n=207, f=1]),\n",
       "   has_mask=True\n",
       " ))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch_dataset[0]\n",
    "\n",
    "\"\"\"\n",
    "    sample is of \n",
    "    - type torch_geometric.data.Data\n",
    "    - shape (window, num_nodes, num_features)\n",
    "\"\"\"\n",
    "sample.x.shape, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 't n f',\n",
       " 'mask': 't n f',\n",
       " 'edge_index': '2 e',\n",
       " 'edge_weight': 'e',\n",
       " 'y': 't n f'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    t = time steps dimension\n",
    "    n = node dimension\n",
    "    e = edge dimension\n",
    "    f = feature dimension\n",
    "    b = batch dimension\n",
    "\"\"\"\n",
    "sample.pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StaticBatch(\n",
       "  input=(x=[b=5, t=18, n=207, f=1], edge_index=[2, e=1515], edge_weight=[e=1515]),\n",
       "  target=(y=[b=5, t=6, n=207, f=1]),\n",
       "  has_mask=True\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch_dataset[:5]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Train dataloader: size=24642}\n",
      "{Validation dataloader: size=2722}\n",
      "{Test dataloader: size=6849}\n",
      "{Predict dataloader: None}\n"
     ]
    }
   ],
   "source": [
    "from tsl.data.datamodule import (SpatioTemporalDataModule,\n",
    "                                 TemporalSplitter)\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize data using mean and std computed over time and node dimensions\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "# Split data sequentially:\n",
    "#   |------------ dataset -----------|\n",
    "#   |--- train ---|- val -|-- test --|\n",
    "splitter = TemporalSplitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the loaders separately for training, validation and testing (for pytorch-lightning, dm can be plugged in as is)\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from tsl.nn.blocks.encoders import RNN\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv\n",
    "from einops.layers.torch import Rearrange  # reshape data with Einstein notation\n",
    "\n",
    "\n",
    "class TimeThenSpaceModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 hidden_size: int = 32,\n",
    "                 rnn_layers: int = 1,\n",
    "                 gnn_kernel: int = 2):\n",
    "        super(TimeThenSpaceModel, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes, hidden_size) # free params learned individually for each node (taming local effects in STGNNs, Cini et al.)\n",
    "\n",
    "        self.time_nn = RNN(input_size=hidden_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           n_layers=rnn_layers,\n",
    "                           cell='gru',\n",
    "                           return_only_last_state=True)\n",
    "        \n",
    "        self.space_nn = DiffConv(in_channels=hidden_size,\n",
    "                                 out_channels=hidden_size,\n",
    "                                 k=gnn_kernel)\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_size, input_size * horizon)\n",
    "        self.rearrange = Rearrange('b n (t f) -> b t n f', t=horizon)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [batch time nodes features]\n",
    "        x_enc = self.encoder(x)  # linear encoder: x_enc = xΘ + b\n",
    "        x_emb = x_enc + self.node_embeddings()  # add node-identifier embeddings\n",
    "        h = self.time_nn(x_emb)  # temporal processing: x=[b t n f] -> h=[b n f]\n",
    "        z = self.space_nn(h, edge_index, edge_weight)  # spatial processing\n",
    "        x_out = self.decoder(z)  # linear decoder: z=[b n f] -> x_out=[b n t⋅f]\n",
    "        x_horizon = self.rearrange(x_out)\n",
    "        return x_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeThenSpaceModel(\n",
      "  (encoder): Linear(in_features=1, out_features=32, bias=True)\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=207, embedding_size=32)\n",
      "  (time_nn): RNN(\n",
      "    (rnn): GRU(32, 32)\n",
      "  )\n",
      "  (space_nn): DiffConv(32, 32)\n",
      "  (decoder): Linear(in_features=32, out_features=6, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=6)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 32   #@param\n",
    "rnn_layers = 1     #@param\n",
    "gnn_kernel = 2     #@param\n",
    "\n",
    "input_size = torch_dataset.n_channels   # 1 channel\n",
    "n_nodes = torch_dataset.n_nodes         # 207 nodes\n",
    "horizon = torch_dataset.horizon         # 12 time steps\n",
    "\n",
    "stgnn = TimeThenSpaceModel(input_size=input_size,\n",
    "                           n_nodes=n_nodes,\n",
    "                           horizon=horizon,\n",
    "                           hidden_size=hidden_size,\n",
    "                           rnn_layers=rnn_layers,\n",
    "                           gnn_kernel=gnn_kernel)\n",
    "print(stgnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape init:  torch.Size([64, 18, 207, 1])\n",
      "x_emb shape:  torch.Size([64, 18, 207, 32])\n",
      "h shape (after time):  torch.Size([64, 207, 32])\n",
      "z shape (after space):  torch.Size([64, 207, 32])\n",
      "x_out shape:  torch.Size([64, 207, 6])\n",
      "x_horizon shape:  torch.Size([64, 6, 207, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Average Loss: 3653.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(stgnn.parameters(), lr=1e-3)\n",
    "\n",
    "stgnn.train()\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x, edge_index, edge_weight, y = batch.x, batch.edge_index, batch.edge_weight, batch.y\n",
    "        \n",
    "        y_hat = stgnn(x, edge_index, edge_weight)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        \n",
    "        progress_bar.set_postfix({\"Batch Loss\": f\"{loss.item():.2f}\"})\n",
    "        break\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / batch_count\n",
    "    tqdm.write(f\"Epoch {epoch + 1}/{epochs} - Average Loss: {avg_epoch_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsl.metrics.torch import MaskedMAE, MaskedMAPE\n",
    "from tsl.engines import Predictor\n",
    "\n",
    "loss_fn = MaskedMAE()\n",
    "\n",
    "metrics = {'mae': MaskedMAE(),\n",
    "           'mape': MaskedMAPE(),\n",
    "           'mae_at_15': MaskedMAE(at=2),  # '2' indicates the third time step,\n",
    "                                          # which correspond to 15 minutes ahead\n",
    "           'mae_at_30': MaskedMAE(at=5),\n",
    "           'mae_at_60': MaskedMAE(at=11)}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model=stgnn,                   # our initialized model\n",
    "    optim_class=torch.optim.Adam,  # specify optimizer to be used...\n",
    "    optim_kwargs={'lr': 0.001},    # ...and parameters for its initialization\n",
    "    loss_fn=loss_fn,               # which loss function to be used\n",
    "    metrics=metrics                # metrics to be logged during train/val/test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /users/hunjael/.conda/envs/torch-st/lib/python3.10/s ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE          | 0      | train\n",
      "1 | train_metrics | MetricCollection   | 0      | train\n",
      "2 | val_metrics   | MetricCollection   | 0      | train\n",
      "3 | test_metrics  | MetricCollection   | 0      | train\n",
      "4 | model         | TimeThenSpaceModel | 18.4 K | train\n",
      "-------------------------------------------------------------\n",
      "18.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.4 K    Total params\n",
      "0.073     Total estimated model params size (MB)\n",
      "29        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "Only args ['edge_index', 'x', 'edge_weight'] are forwarded to the model (TimeThenSpaceModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 100/100 [00:57<00:00,  1.73it/s, v_num=0, val_mae=6.830, val_mae_at_15=7.440, val_mae_at_30=6.590, val_mae_at_60=0.000, val_mape=0.146, train_mae=216.0, train_mae_at_15=220.0, train_mae_at_30=217.0, train_mae_at_60=0.000, train_mape=3.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 100/100 [00:57<00:00,  1.73it/s, v_num=0, val_mae=6.830, val_mae_at_15=7.440, val_mae_at_30=6.590, val_mae_at_60=0.000, val_mape=0.146, train_mae=216.0, train_mae_at_15=220.0, train_mae_at_30=217.0, train_mae_at_60=0.000, train_mape=3.870]\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1,\n",
    "                     limit_train_batches=100,  # end an epoch after 100 updates\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n",
      "Predictor with already instantiated model is loading a state_dict from /users/hunjael/Projects/temporal-gnn/notebooks/logs/epoch=0-step=100.ckpt. Cannot  check if model hyperparameters are the same.\n",
      "/users/hunjael/.conda/envs/torch-st/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 108/108 [00:09<00:00, 11.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            7.691833019256592\n",
      "        test_mae             8.043513298034668\n",
      "     test_mae_at_15          8.828991889953613\n",
      "     test_mae_at_30          7.726053237915039\n",
      "     test_mae_at_60                 0.0\n",
      "        test_mape           0.17782194912433624\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model(checkpoint_callback.best_model_path)\n",
    "predictor.freeze()\n",
    "\n",
    "trainer.test(predictor, datamodule=dm);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
